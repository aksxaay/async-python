{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*disclaimer* only to be used for this article and nothing else\n",
    "[An Introduction to Asynchronous Programming in Python](https://medium.com/velotio-perspectives/an-introduction-to-asynchronous-programming-in-python-af0189a88bbb)\n",
    "\n",
    "that being said Good luck man, you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Asynchronous Programming in Python\n",
    "\n",
    "## Introduction\n",
    "Asynchronous programming is a type of parallel programming in which a unit of work is allowed to run separately from the primary application thread. When the work is complete, it notifies the main thread about completion or failure of the worker thread. There are numerous benefits to using it, such as improved application performance and enhanced responsiveness.\n",
    "\n",
    "![difference](https://miro.medium.com/max/540/1*t_oCyHBstMnF8WpZ67pKTg.jpeg)\n",
    "\n",
    "For example, instead of waiting for an HTTP request to finish before continuing execution, with Python async coroutines you can submit the request and do other work that’s waiting in a queue while waiting for the HTTP request to finish.\n",
    "Asynchronicity seems to be a big reason why Node.js so popular for server-side programming. Much of the code we write, especially in heavy IO applications like websites, depends on external resources. This could be anything from a remote database call to **POSTing** to a **REST** service. As soon as you ask for any of these resources, your code is waiting around with nothing to do. With asynchronous programming, you allow your code to handle other tasks while waiting for these other resources to respond.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multiple Processes\n",
    "The most obvious way is to use multiple processes. From the terminal, you can start your script two, three, four…ten times and then all the scripts are going to run independently or at the same time. The operating system that’s underneath will take care of sharing your **CPU** resources among all those instances. Alternately you can use the **multiprocessing library** which supports *spawning processes* as shown in the example below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of continent is :  AsiaThe name of continent is : \n",
      " AmericaThe name of continent is :  \n",
      "EuropeThe name of continent is : \n",
      " Africa\n"
     ]
    }
   ],
   "source": [
    "# Code Deomonstrating Multiple Processes\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "def print_func(continent='Asia'):\n",
    "    print('The name of continent is : ', continent)\n",
    "\n",
    "if __name__ == \"__main__\":  # confirms that the code is under main function\n",
    "    names = ['America', 'Europe', 'Africa']\n",
    "    procs = []\n",
    "    proc = Process(target=print_func)  # instantiating without any argument\n",
    "    procs.append(proc)\n",
    "    proc.start()\n",
    "\n",
    "    # instantiating process with arguments\n",
    "    for name in names:\n",
    "        # print(name)\n",
    "        proc = Process(target=print_func, args=(name,))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "\n",
    "    # complete the processes\n",
    "    for proc in procs:\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multiple Threads\n",
    "The next way to run multiple things at once is to use **threads**. A thread is a line of execution, pretty much like a process, *but you can have multiple threads in the context of one process and they all share access to common resources*. But because of this, it’s difficult to write a threading code. And again, the operating system is doing all the heavy lifting on sharing the CPU, but the global interpreter lock (GIL) allows only one thread to run Python code at a given time even when you have multiple threads running code. So, In CPython(CPython is the reference implementation of the Python programming language.), the GIL prevents multi-core concurrency. Basically, you’re running in a single core even though you may have two or four or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square: 100\n",
      "Cube: 1000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Code Demonstration of Multiple Threading\n",
    "\n",
    "import threading\n",
    "\n",
    "def print_cube(num):\n",
    "    \"\"\"\n",
    "    function to print cube of given num\n",
    "    \"\"\"\n",
    "    print(\"Cube: {}\".format(num * num * num))\n",
    " \n",
    "def print_square(num):\n",
    "    \"\"\"\n",
    "    function to print square of given num\n",
    "    \"\"\"\n",
    "    print(\"Square: {}\".format(num * num))\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    # creating thread\n",
    "    t1 = threading.Thread(target=print_square, args=(10,))\n",
    "    t2 = threading.Thread(target=print_cube, args=(10,))\n",
    " \n",
    "    # starting thread 1\n",
    "    t1.start()\n",
    "    # starting thread 2\n",
    "    t2.start()\n",
    " \n",
    "    # wait until thread 1 is completely executed\n",
    "    t1.join()\n",
    "    # wait until thread 2 is completely executed\n",
    "    t2.join()\n",
    " \n",
    "    # both threads completely executed\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coroutines using yield:\n",
    "Coroutines are generalization of **subroutines**. They are used for cooperative multitasking where a process voluntarily yield (give away) control periodically or when idle in order to enable multiple applications to be run simultaneously. Coroutines are similar to generators but with few extra methods and slight change in how we use yield statement. Generators produce data for iteration while coroutines can also consume data.\n",
    "\n",
    "Subroutines - `mini programs` within a large program.\n",
    "        Breaking down or decomposing a complex programming task into smaller sub-tasks and writing each of these as subroutines, makes the problem easier to solve\n",
    "\n",
    "\n",
    "### yield\n",
    "The yield statement suspends function’s execution and sends a value back to the caller, but *retains enough state* to enable function to resume where it is left off. When resumed, the function continues execution immediately *after the last yield run*. This allows its code to produce a series of values over time, rather than computing them at once and sending them back like a list.\n",
    "\n",
    "sends a series of values over time > sending back a list\n",
    "\n",
    "Technically speaking, a Python iterator object must implement two special methods, `__iter__()` and `__next__()`, collectively called the **iterator protocol**.\n",
    "\n",
    "`corou.__next__()`\n",
    "`next(corou)`\n",
    "\n",
    "both syntax is correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching prefix:Dear\n",
      "Dear James\n",
      "Closing coroutine!!\n"
     ]
    }
   ],
   "source": [
    "def print_name(prefix):\n",
    "    print(\"Searching prefix:{}\".format(prefix))\n",
    "    try : \n",
    "        while True:\n",
    "                # yield used to create coroutine (yield is keyword)\n",
    "                name = (yield)\n",
    "                if prefix in name:\n",
    "                    print(name)\n",
    "    except GeneratorExit:\n",
    "            print(\"Closing coroutine!!\")\n",
    " \n",
    "corou = print_name(\"Dear\")\n",
    "# this skips a value both syntax corrent \n",
    "# corou.__next__()\n",
    "next(corou)\n",
    "\n",
    "# methods of class generator.\n",
    "# becomes generator when yield is used in function body.\n",
    "corou.send(\"James\")\n",
    "corou.send(\"Dear James\")\n",
    "# print(type(corou), dir(corou), corou, sep='\\n')\n",
    "corou.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "can send anything over\n"
     ]
    }
   ],
   "source": [
    "# Understanding how Yield works\n",
    "\n",
    "# yield is a really wild return statement\n",
    "\n",
    "def simpleGeneratorFun():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3\n",
    "    yield 'can send anything over'\n",
    "  \n",
    "# Driver code to check above generator function\n",
    "for value in simpleGeneratorFun(): \n",
    "    print(value)\n",
    "    # print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Return** sends a specified value back to its caller whereas **Yield** can produce a sequence of values. We should use yield when we want to iterate over a sequence, but don’t want to store the entire sequence in memory.\n",
    "\n",
    "Yield are used in Python **generators**. A generator function is defined like a normal function, but whenever it needs to generate a value, it does so with the yield keyword rather than return. **IMP** *If the body of a def contains yield, the function automatically becomes a generator function.*\n",
    "\n",
    "if it contains yield it becomes a generator function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Asynchronous Programming\n",
    "The fourth way is an asynchronous programming, where the **OS is not participating**. As far as OS is concerned you’re going to have one process and there’s going to be a single thread within that process, but you’ll be able to do multiple things at once. So, what’s the trick?\n",
    "*The answer is asyncio*\\\n",
    "asyncio is the new concurrency module introduced in Python 3.4. It is designed to use coroutines and futures to simplify asynchronous code and make it almost as *readable as synchronous code* as there are no callbacks.\n",
    "\n",
    "\n",
    "**asyncio** uses different constructs: *event loops, coroutines and futures.*\n",
    "More like Js experience then\n",
    "\n",
    "\n",
    "* An event loop manages and distributes the execution of different tasks. It registers them and handles distributing the flow of control between them.\n",
    "\n",
    "\n",
    "* Coroutines (covered above) are special functions that work similarly to Python generators, on await they release the flow of control back to the event loop. A coroutine needs to be scheduled to run on the event loop, once scheduled coroutines are wrapped in Tasks which is a type of Future.\n",
    "\n",
    "\n",
    "* Futures represent the result of a task that may or may not have been executed. This result may be an exception.\\\n",
    "\n",
    "Using *Asyncio*, you can structure your code so `subtasks are defined as coroutines` and allows you to schedule them as you please, including simultaneously. Coroutines contain yield points where we define possible points where a context switch can happen if other tasks are pending, but will not if no other task is pending.\n",
    "A context switch in asyncio represents the event loop yielding the flow of control from one coroutine to the next.\n",
    "In the example, we run 3 async tasks that query Reddit separately, extract and print the JSON. We leverage aiohttp which is a http client library ensuring even the HTTP request runs asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-47' coro=<get_reddit_top() running at <ipython-input-5-c6253fecffdb>:24>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-45' coro=<get_reddit_top() done, defined at <ipython-input-5-c6253fecffdb>:24> exception=AssertionError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-c6253fecffdb>\", line 25, in get_reddit_top\n",
      "    data1 = await get_json(client, 'https://www.reddit.com/r/' + subreddit + '/top.json?sort=top&t=day&limit=5')\n",
      "  File \"<ipython-input-5-c6253fecffdb>\", line 18, in get_json\n",
      "    assert response.status == 200\n",
      "AssertionError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-46' coro=<get_reddit_top() done, defined at <ipython-input-5-c6253fecffdb>:24> exception=AssertionError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-c6253fecffdb>\", line 25, in get_reddit_top\n",
      "    data1 = await get_json(client, 'https://www.reddit.com/r/' + subreddit + '/top.json?sort=top&t=day&limit=5')\n",
      "  File \"<ipython-input-5-c6253fecffdb>\", line 18, in get_json\n",
      "    assert response.status == 200\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "# defining custom handlers to be executed when a signal is received\n",
    "import signal\n",
    "import asyncio\n",
    "\n",
    "# Asynchronous HTTP Client/Server for asyncio and Python.\n",
    "import sys\n",
    "import aiohttp\n",
    "import json\n",
    "\n",
    "# created event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "# Client session is the recommended interface for making HTTP requests.\n",
    "# initiated Session\n",
    "client = aiohttp.ClientSession(loop=loop)\n",
    "\n",
    "async def get_json(client, url):  \n",
    "    async with client.get(url) as response:\n",
    "        assert response.status == 200\n",
    "        return await response.read()\n",
    "\n",
    "\n",
    "# https://www.reddit.com/r/%7Bsubreddit%7D/top.json?sort=top&t=day&limit=5\n",
    "# returns json\n",
    "async def get_reddit_top(subreddit, client):  \n",
    "    data1 = await get_json(client, 'https://www.reddit.com/r/' + subreddit + '/top.json?sort=top&t=day&limit=5')\n",
    "\n",
    "    j = json.loads(data1.decode('utf-8'))\n",
    "    for i in j['data']['children']:\n",
    "        score = i['data']['score']\n",
    "        title = i['data']['title']\n",
    "        link = i['data']['url']\n",
    "        print(str(score) + ': ' + title + ' (' + link + ')')\n",
    "        print('\\n \\n \\n ')\n",
    "\n",
    "    print('DONE:', subreddit + '\\n')\n",
    "\n",
    "def signal_handler(signal, frame):  \n",
    "    loop.stop()\n",
    "    client.close()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "asyncio.ensure_future(get_reddit_top('python', client))  \n",
    "asyncio.ensure_future(get_reddit_top('programming', client))  \n",
    "asyncio.ensure_future(get_reddit_top('compsci', client))  \n",
    "# loop.run_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[asyncio // stackoverflow difference between python3 and jupyter](https://stackoverflow.com/questions/55409641/asyncio-run-cannot-be-called-from-a-running-event-loop)\n",
    "\n",
    "`asyncio.run(main())` - Python (≥ 3.7)\n",
    "`await main()` - Jupyter / iPython\n",
    "\n",
    "somehow jupyter is already running an event loop\n",
    "\n",
    "\n",
    "Real Python // asyncio\n",
    "**Parallelism** consists of performing multiple operations at the same time. **Multiprocessing** is a means to effect parallelism, and it entails spreading tasks over a computer’s central processing units (CPUs, or cores). Multiprocessing is well-suited for CPU-bound tasks: tightly bound for loops and mathematical computations usually fall into this category.\\\n",
    "\n",
    "**Concurrency** is a slightly broader term than parallelism. It suggests that multiple tasks have the ability to run in an overlapping manner. *(There’s a saying that concurrency does not imply parallelism.)*\n",
    "\n",
    "GIL - Global Interpreter Lock\n",
    "The Python Global Interpreter Lock or GIL, in simple words, is a mutex (or a lock) that allows only one thread to hold the control of the Python interpreter.\n",
    "\n",
    "This means that only one thread can be in a state of execution at any point in time. The impact of the GIL isn’t visible to developers who execute single-threaded programs, but it can be a performance bottleneck in CPU-bound and multi-threaded code.\n",
    "\n",
    "Since the GIL allows only one thread to execute at a time even in a multi-threaded architecture with more than one CPU core, the GIL has gained a reputation as an “infamous” feature of Python.\n",
    "\n",
    "[Real python // GIL](https://realpython.com/python-gil/)\n",
    "GIL is a necessary Devil?\n",
    "\n",
    "This is how we're circumventing GIL\n",
    "> **Multi-processing** vs **multi-threading**: The most popular way is to use a multi-processing approach where you use multiple processes instead of threads. Each Python process gets its own *Python interpreter* and memory space so the GIL won’t be a problem. Python has a **multiprocessing** module which lets us create processes easily like this:\n",
    "\n",
    "below are code examples to help illustrate the differences.\n",
    "Different threads don't help due to GIL, \n",
    "however, Multiprocessing helps.\n",
    "there is a little bit of overhead cost, but overall its pog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/multiprocessing/context.py:118: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  from .pool import Pool\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds - 2.554898262023926\n"
     ]
    }
   ],
   "source": [
    "# MULTIPROCESSING MODULE\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "COUNT = 50000000\n",
    "def countdown(n):\n",
    "    while n>0:\n",
    "        n -= 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(processes=2)\n",
    "    start = time.time()\n",
    "    r1 = pool.apply_async(countdown, [COUNT//2])\n",
    "    r2 = pool.apply_async(countdown, [COUNT//2])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    end = time.time()\n",
    "    print('Time taken in seconds -', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds - 3.671034812927246\n"
     ]
    }
   ],
   "source": [
    "# single_threaded.py\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "COUNT = 50000000\n",
    "\n",
    "def countdown(n):\n",
    "    while n>0:\n",
    "        n -= 1\n",
    "\n",
    "start = time.time()\n",
    "countdown(COUNT)\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken in seconds -', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds - 4.623546123504639\n"
     ]
    }
   ],
   "source": [
    "# multi_threaded.py\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "COUNT = 50000000\n",
    "\n",
    "def countdown(n):\n",
    "    while n>0:\n",
    "        n -= 1\n",
    "\n",
    "t1 = Thread(target=countdown, args=(COUNT//2,))\n",
    "t2 = Thread(target=countdown, args=(COUNT//2,))\n",
    "\n",
    "start = time.time()\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken in seconds -', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "bye\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    print('hello')\n",
    "    await asyncio.sleep(1)\n",
    "    print('bye')\n",
    "\n",
    "await (main())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
